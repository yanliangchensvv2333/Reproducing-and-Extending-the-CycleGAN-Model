{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "toc_visible": true,
      "mount_file_id": "https://github.com/zhisheng-hua/Reproducing-and-Extending-the-CycleGAN-Model/blob/cy/CycleGAN_Draft1.ipynb",
      "authorship_tag": "ABX9TyO+ga/YGN3RTxRysfVWd1XB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhisheng-hua/Reproducing-and-Extending-the-CycleGAN-Model/blob/main/CycleGAN_Draft1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ],
      "metadata": {
        "id": "TSEh-iK-I7d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dCvQHGCSJfGL",
        "outputId": "2cb25cda-b8b9-4414-eabb-2aba8f179e3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "j-OVhbBGfISI"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.utils import save_image\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "wHGc09O3NG6X"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters and Constant Variables"
      ],
      "metadata": {
        "id": "6bVWAUIxVojW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", DEVICE)"
      ],
      "metadata": {
        "id": "-vxmIPcJ3KLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38fb8b3b-935b-440c-a9e7-9bd019ed3ca7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIR = \"/content/drive/MyDrive/ECE-GY 6953 DL/Project/Datasets/horse2zebra/\"\n",
        "TRAIN_A_PATH = DATASET_DIR + \"trainA\"\n",
        "TRAIN_B_PATH = DATASET_DIR + \"trainA\"\n",
        "TEST_A_PATH = DATASET_DIR + \"testA\"\n",
        "TEST_B_PATH = DATASET_DIR + \"testA\"\n",
        "\n",
        "MODEL_DIR = \"/content/drive/MyDrive/ECE-GY 6953 DL/Project/SavedModels/\"\n",
        "\n",
        "VISUAL_DIR = \"/content/drive/MyDrive/ECE-GY 6953 DL/Project/Visualizations/\""
      ],
      "metadata": {
        "id": "LD1k80gisQqY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "NUM_EPOCHS = 10\n",
        "NUM_EPOCHS_DECAY = 0 # the number of last epoches during which lr decays to 0\n",
        "\n",
        "LR = 0.0002\n",
        "LAMBDA_CYCLE = 10.0\n",
        "LAMBDA_IDT = 0.5\n",
        "IMAGE_POOL_SIZE = 50\n",
        "\n",
        "MAX_NUM_SAMPLES = 2000 # if larger than the number of training/testing samples, use all samples\n",
        "NUM_DATALOADER_WORKERS = 2\n",
        "SAVE_MODELS = False\n",
        "SAVE_LOSS_PLOTS = False"
      ],
      "metadata": {
        "id": "lKEvvEdRVn3V"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "7XlppgzSw4uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The code in this cell is adapted from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git.\n",
        "\n",
        "# Method to obtain/insert images from/into the image pool\n",
        "def query_image_pool(image_pool, pool_size, curr_images):\n",
        "  if pool_size == 0:\n",
        "      return curr_images\n",
        "  ret_images = []\n",
        "  for image in curr_images:\n",
        "      image = torch.unsqueeze(image.data, 0)\n",
        "      if len(image_pool) < pool_size: # if buffer is not full\n",
        "          image_pool.append(image)\n",
        "          ret_images.append(image)\n",
        "      else: # if buffer is full\n",
        "          # by 50% chance, return an old image from the pool and replace it with\n",
        "          # a current image; otherwise, return the current image\n",
        "          p = random.uniform(0, 1)\n",
        "          if p > 0.5:\n",
        "              random_id = random.randint(0, pool_size - 1)\n",
        "              old_image = image_pool[random_id].clone()\n",
        "              image_pool[random_id] = image\n",
        "              ret_images.append(old_image)\n",
        "          else:\n",
        "              ret_images.append(image)\n",
        "  return torch.cat(ret_images, 0)"
      ],
      "metadata": {
        "id": "rR7l18OIBsCD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code in this cell is adapted from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git.\n",
        "\n",
        "# Method to initialize weights of the given model\n",
        "def init_weights(model):\n",
        "  def init_func(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "      init.normal_(m.weight.data, 0.0, 0.02)\n",
        "      if hasattr(m, 'bias') and m.bias is not None:\n",
        "          init.constant_(m.bias.data, 0.0)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "      init.normal_(m.weight.data, 1.0, 0.02)\n",
        "      init.constant_(m.bias.data, 0.0)\n",
        "  model.apply(init_func)"
      ],
      "metadata": {
        "id": "XeEC6hCH9A8o"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code in this cell is adapted from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git.\n",
        "\n",
        "# Method to post-processing the output image of the generator\n",
        "def post_processing_image(image):\n",
        "  image = image.cpu().float().numpy()\n",
        "  image_np = (np.transpose(image, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
        "  return image_np.astype(np.uint8)"
      ],
      "metadata": {
        "id": "_0gl56YpxCb0"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "xorqpTpAV18P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, A_dir, B_dir, transform, random_pairs=True):\n",
        "        self.A_dir = A_dir\n",
        "        self.B_dir = B_dir\n",
        "        self.transform = transform\n",
        "        self.random_pairs = random_pairs\n",
        "\n",
        "        self.A_img_filenames = os.listdir(self.A_dir)[:MAX_NUM_SAMPLES]\n",
        "        self.B_img_filenames = os.listdir(self.B_dir)[:MAX_NUM_SAMPLES]\n",
        "        self.A_size = len(self.A_img_filenames)\n",
        "        self.B_size = len(self.B_img_filenames)\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(self.A_size, self.B_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        A_img_path = os.path.join(self.A_dir,\n",
        "                                  self.A_img_filenames[index % self.A_size])\n",
        "        if self.random_pairs:\n",
        "          B_index = random.randint(0, self.B_size - 1)\n",
        "        else:\n",
        "          B_index = index % self.B_size\n",
        "        B_img_path = os.path.join(self.B_dir, self.B_img_filenames[B_index])\n",
        "\n",
        "        A_img = self.transform(Image.open(A_img_path).convert(\"RGB\"))\n",
        "        B_img = self.transform(Image.open(B_img_path).convert(\"RGB\"))\n",
        "\n",
        "        return A_img, B_img"
      ],
      "metadata": {
        "id": "TNYKRpXTV6GP"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image transformation\n",
        "train_data_transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "test_data_transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "e9J4e-ONnS11"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup datasets and dataloaders\n",
        "train_dataset = CustomDataset(TRAIN_A_PATH, TRAIN_B_PATH, train_data_transform,\n",
        "                              random_pairs=True)\n",
        "test_dataset = CustomDataset(TEST_A_PATH, TEST_B_PATH, test_data_transform,\n",
        "                             random_pairs=False)\n",
        "print(\"Number of training samples:\", len(train_dataset))\n",
        "print(\"Number of testing samples:\", len(train_dataset))\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                shuffle=True,\n",
        "                                                num_workers=NUM_DATALOADER_WORKERS)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=False,\n",
        "                                               num_workers=NUM_DATALOADER_WORKERS)"
      ],
      "metadata": {
        "id": "-YQFxRVa3vXe",
        "outputId": "80846992-6b6a-4d7b-e169-ef0bf9a16e06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 1067\n",
            "Number of testing samples: 1067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "xg-7OTQ5riva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator"
      ],
      "metadata": {
        "id": "YqZAcAJJSXEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel, kernel_size, stride, padding, use_leaky=False, use_norm=True, use_acv=True):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding, bias=True)\n",
        "    if use_norm:\n",
        "      self.norm = nn.InstanceNorm2d(out_channel)\n",
        "    else:\n",
        "      self.norm = nn.Identity()\n",
        "    if not use_acv:\n",
        "      self.acv = nn.Identity()\n",
        "    elif use_leaky:\n",
        "      self.acv = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "    else:\n",
        "      self.acv = nn.ReLU(inplace=True)\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.norm(x)\n",
        "    return self.acv(x)"
      ],
      "metadata": {
        "id": "KMhkBIsOSWZx"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpsamlingBlock(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel, use_dropout=False, p=0.5):\n",
        "    super().__init__()\n",
        "    self.use_dropout = use_dropout\n",
        "    self.conv = nn.ConvTranspose2d(in_channel, out_channel, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "    self.norm = nn.InstanceNorm2d(out_channel)\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.acv = nn.ReLU(inplace=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.norm(x)\n",
        "    if self.use_dropout:\n",
        "      x = self.dropout(x)\n",
        "    return self.acv(x)"
      ],
      "metadata": {
        "id": "KrLh75O6Apfn"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "  def __init__(self, channel, p=0.5):\n",
        "    super().__init__()\n",
        "    self.padding = nn.ReflectionPad2d(1)\n",
        "    self.conv1 = ConvBlock(channel, channel, kernel_size=3, stride=1, padding=0, use_norm=True)\n",
        "    self.conv2 = ConvBlock(channel, channel, kernel_size=3, stride=1, padding=0, use_norm=True, use_acv=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.padding(x)\n",
        "    x1 = self.conv1(x1)\n",
        "    x1 = self.padding(x1)\n",
        "    x1 = self.conv2(x1)\n",
        "    return x + x1"
      ],
      "metadata": {
        "id": "u6cqvJqZuvW1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel, res_block_num=9):\n",
        "    super().__init__()\n",
        "    layers = []\n",
        "    reflect_pad = nn.ReflectionPad2d(3)\n",
        "    layers += [reflect_pad, \n",
        "          ConvBlock(in_channel, 64, kernel_size=7, stride=1, padding=0, use_leaky=False, use_norm=True, use_acv=True),\n",
        "          ConvBlock(64, 128, kernel_size=3, stride=2, padding=1, use_leaky=False, use_norm=True, use_acv=True),\n",
        "          ConvBlock(128, 256, kernel_size=3, stride=2, padding=1, use_leaky=False, use_norm=True, use_acv=True),\n",
        "          ]\n",
        "    for i in range(res_block_num):\n",
        "      layers += [ResBlock(256)]\n",
        "    \n",
        "    layers += [UpsamlingBlock(256, 128, use_dropout=False),\n",
        "          UpsamlingBlock(128, 64, use_dropout=False)\n",
        "          ]\n",
        "    layers += [reflect_pad,\n",
        "          nn.Conv2d(64, out_channel, kernel_size=7, padding=0),\n",
        "          nn.Tanh(),\n",
        "          ]\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "    \n"
      ],
      "metadata": {
        "id": "bd4faoHsux50"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator"
      ],
      "metadata": {
        "id": "nBs6pDsiSd-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channel):\n",
        "    super().__init__()\n",
        "    self.conv1 = ConvBlock(in_channel, 64, kernel_size=4, stride=2, padding=1, use_leaky=True, use_norm=False, use_acv=True)\n",
        "    self.conv2 = ConvBlock(64, 128, kernel_size=4, stride=2, padding=1, use_leaky=True, use_norm=True, use_acv=True)\n",
        "    self.conv3 = ConvBlock(128, 256, kernel_size=4, stride=2, padding=1, use_leaky=True, use_norm=True, use_acv=True)\n",
        "    self.conv4 = ConvBlock(256, 512, kernel_size=4, stride=2, padding=1, use_leaky=True, use_norm=True, use_acv=True)\n",
        "    self.output = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    return self.output(x)\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "M8T-FBTESrPw"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CycleGAN"
      ],
      "metadata": {
        "id": "ol9q-KBJcBq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to train CycleGAN for one epoch\n",
        "# Combine generators and discriminators together\n",
        "# Calculate losses and backpropagation\n",
        "def train_CycleGAN_for_one_epoch(G_A, D_B, G_B, D_A,\n",
        "                                 cri_GAN, cri_Cycle, cri_Idt,\n",
        "                                 opt_G, opt_D,\n",
        "                                 data_loader,\n",
        "                                 use_image_pools=False, image_pools=None):\n",
        "  model_name = \"CycleGAN_\" + os.path.basename(DATASET_DIR[:-1])\n",
        "\n",
        "  avg_loss_G = 0\n",
        "  avg_loss_D_B = 0 # Discriminator for A->B\n",
        "  avg_loss_D_A = 0 # Discriminator for B->A\n",
        "\n",
        "  G_A.train()\n",
        "  D_B.train()\n",
        "  G_B.train()\n",
        "  D_A.train()\n",
        "\n",
        "  # labels for discriminators\n",
        "  D_labels_real = None\n",
        "  D_labels_fake = None\n",
        "\n",
        "  for i, (A_real, B_real) in enumerate(tqdm(data_loader)):\n",
        "    A_real = A_real.to(DEVICE)\n",
        "    B_real = B_real.to(DEVICE)\n",
        "\n",
        "    # forward pass; generate fake images\n",
        "    B_fake = G_A(A_real) # G_A(A)\n",
        "    A_fake = G_B(B_real) # G_B(B)\n",
        "\n",
        "    # if use old generated images to train discriminators\n",
        "    if use_image_pools:\n",
        "      B_fake_for_D = query_image_pool(image_pools['B'], IMAGE_POOL_SIZE,\n",
        "                                      B_fake.detach())\n",
        "      A_fake_for_D = query_image_pool(image_pools['A'], IMAGE_POOL_SIZE,\n",
        "                                      A_fake.detach())\n",
        "      if i == 0:\n",
        "        model_name += \"_ImagePool\"\n",
        "    else:\n",
        "      B_fake_for_D = B_fake.detach()\n",
        "      A_fake_for_D = A_fake.detach()\n",
        "      if i == 0:\n",
        "        model_name += \"_NoImagePool\"\n",
        "\n",
        "    ### Update discriminators\n",
        "    opt_D.zero_grad()\n",
        "    ## Update D_B (discriminator for A->B)\n",
        "    # Real images\n",
        "    D_B_real_output = D_B(B_real)\n",
        "    if i == 0: # initialize Ds' labels; only do once\n",
        "      D_labels_real = torch.ones(D_B_real_output.shape).to(DEVICE)\n",
        "      D_labels_fake = torch.zeros(D_B_real_output.shape).to(DEVICE)\n",
        "    loss_D_B_real = cri_GAN(D_B_real_output, D_labels_real)\n",
        "    # Fake images\n",
        "    loss_D_B_fake = cri_GAN(D_B(B_fake_for_D), D_labels_fake)\n",
        "    # Combine losses and compute gradients\n",
        "    loss_D_B = (loss_D_B_real + loss_D_B_fake) * 0.5\n",
        "    loss_D_B.backward()\n",
        "    ## Update D_A (discriminator for B->A)\n",
        "    # Real images\n",
        "    loss_D_A_real = cri_GAN(D_A(A_real), D_labels_real)\n",
        "    # Fake images\n",
        "    loss_D_A_fake = cri_GAN(D_A(A_fake_for_D), D_labels_fake)\n",
        "    # Combine losses and compute gradients\n",
        "    loss_D_A = (loss_D_A_real + loss_D_A_fake) * 0.5\n",
        "    loss_D_A.backward()\n",
        "    # Update the optimizer\n",
        "    opt_D.step()\n",
        "\n",
        "    ### Update generators\n",
        "    opt_G.zero_grad()\n",
        "    # GAN losses\n",
        "    loss_GAN_G_A = cri_GAN(D_B(B_fake), D_labels_real)\n",
        "    loss_GAN_G_B = cri_GAN(D_A(A_fake), D_labels_real)\n",
        "    # Cycle losses\n",
        "    loss_Cycle_G_A = cri_Cycle(G_B(B_fake), A_real) # loss(G_B(G_A(A)), A)\n",
        "    loss_Cycle_G_B = cri_Cycle(G_A(A_fake), B_real) # loss(G_A(G_B(B)), B)\n",
        "    # Identity losses\n",
        "    loss_Idt_G_A = cri_Idt(G_A(B_real), B_real) # loss(G_A(B), B)\n",
        "    loss_Idt_G_B = cri_Idt(G_B(A_real), A_real) # loss(G_B(A), A)\n",
        "    # Combine all losses\n",
        "    loss_G = (loss_GAN_G_A + loss_GAN_G_B\n",
        "              + LAMBDA_CYCLE * (loss_Cycle_G_A + loss_Cycle_G_B\n",
        "                                + LAMBDA_IDT * (loss_Idt_G_A + loss_Idt_G_B)))\n",
        "    # Update\n",
        "    loss_G.backward()\n",
        "    opt_G.step()\n",
        "\n",
        "    avg_loss_G += loss_G.item()\n",
        "    avg_loss_D_B += loss_D_B.item()\n",
        "    avg_loss_D_A += loss_D_A.item()\n",
        "\n",
        "  avg_loss_G = avg_loss_G / len(data_loader)\n",
        "  avg_loss_D_B = avg_loss_D_B / len(data_loader)\n",
        "  avg_loss_D_A = avg_loss_D_A / len(data_loader)\n",
        "\n",
        "  return model_name, (avg_loss_G, avg_loss_D_B, avg_loss_D_A)"
      ],
      "metadata": {
        "id": "2HGs3VEMhiSe"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Y_tLfkrbvZp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training setup\n",
        "\n",
        "# Generator and Discriminator models\n",
        "# Mapping A->B\n",
        "G_A = Generator(in_channel=3, out_channel=3).to(DEVICE)\n",
        "D_B = Discriminator(in_channel=3).to(DEVICE)\n",
        "# # Mapping B->A\n",
        "G_B = Generator(in_channel=3, out_channel=3).to(DEVICE)\n",
        "D_A = Discriminator(in_channel=3).to(DEVICE)\n",
        "\n",
        "# Initialize the weights of models\n",
        "init_weights(G_A)\n",
        "init_weights(D_B)\n",
        "init_weights(G_B)\n",
        "init_weights(D_A)\n",
        "\n",
        "# Losses\n",
        "cri_GAN = nn.MSELoss() # Least-Squares GAN; see Reference 35 of the paper\n",
        "cri_Cycle = nn.L1Loss()\n",
        "cri_Idt = nn.L1Loss()\n",
        "\n",
        "# Optimizers\n",
        "opt_G = torch.optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()),\n",
        "                         lr=LR, betas=(0.5, 0.999))\n",
        "opt_D = torch.optim.Adam(itertools.chain(D_B.parameters(), D_A.parameters()),\n",
        "                         lr=LR, betas=(0.5, 0.999))\n",
        "\n",
        "# Image pools\n",
        "image_pools = {'A': [], 'B': []}\n",
        "\n",
        "# Schedulers for learning rate decay\n",
        "def lambda_rule(epoch): # adapted from authors' Github repo \n",
        "  lr_l = 1.0 - max(0, epoch - (NUM_EPOCHS - NUM_EPOCHS_DECAY)) / float(NUM_EPOCHS_DECAY + 1)\n",
        "  return lr_l\n",
        "sclr_G = lr_scheduler.LambdaLR(opt_G, lr_lambda=lambda_rule)\n",
        "sclr_D = lr_scheduler.LambdaLR(opt_D, lr_lambda=lambda_rule)"
      ],
      "metadata": {
        "id": "jm-YnUgjyVR7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for all epoches\n",
        "losses_G = []\n",
        "losses_D_B = []\n",
        "losses_D_A = []\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "  print(\"Epoch: {} / {}\".format(epoch, NUM_EPOCHS))\n",
        "\n",
        "  # Training process\n",
        "  model_name, stats = train_CycleGAN_for_one_epoch(G_A, D_B, G_B, D_A,\n",
        "                                                   cri_GAN, cri_Cycle, cri_Idt,\n",
        "                                                   opt_G, opt_D,\n",
        "                                                   train_data_loader,\n",
        "                                                   use_image_pools=True,\n",
        "                                                   image_pools=image_pools)\n",
        "  sclr_G.step()\n",
        "  sclr_D.step()\n",
        "\n",
        "  losses_G.append(stats[0])\n",
        "  losses_D_B.append(stats[1])\n",
        "  losses_D_A.append(stats[2])\n",
        "\n",
        "  if epoch == NUM_EPOCHS:\n",
        "    print()\n",
        "  print(\"----------------------------------------------------------------------------------\")\n",
        "  print(\"  Loss G: %f, Loss D_B: %f, Loss D_A: %f, Next LR: %f\" % (\n",
        "      stats[0], stats[1], stats[2], sclr_G.get_last_lr()[0]\n",
        "  ))\n",
        "  print(\"----------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "SKNcY7VNyvWu",
        "outputId": "0a6abb1c-9d0b-4e46-e5c8-787631eea527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1067/1067 [03:12<00:00,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------\n",
            "  Loss G: 8.343364, Loss D_B: 0.327094, Loss D_A: 0.323646, Next LR: 0.000200\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1067/1067 [03:10<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------\n",
            "  Loss G: 7.435760, Loss D_B: 0.243489, Loss D_A: 0.246660, Next LR: 0.000200\n",
            "----------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 29/1067 [00:05<03:09,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-793f5dc06650>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# Training process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   model_name, stats = train_CycleGAN_for_one_epoch(G_A, D_B, G_B, D_A,\n\u001b[0m\u001b[1;32m     10\u001b[0m                                                    \u001b[0mcri_GAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcri_Cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcri_Idt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                    \u001b[0mopt_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-dff71203fc9b>\u001b[0m in \u001b[0;36mtrain_CycleGAN_for_one_epoch\u001b[0;34m(G_A, D_B, G_B, D_A, cri_GAN, cri_Cycle, cri_Idt, opt_G, opt_D, data_loader, use_image_pools, image_pools)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Identity losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mloss_Idt_G_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcri_Idt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_real\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# loss(G_A(B), B)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mloss_Idt_G_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcri_Idt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_real\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# loss(G_B(A), A)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Combine all losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     loss_G = (loss_GAN_G_A + loss_GAN_G_B\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-6a11b363f5b6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-ef5471a52338>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-cc710c2e4148>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_no_batch_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_instance_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36m_apply_instance_norm\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_instance_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         return F.instance_norm(\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             self.training or not self.track_running_stats, self.momentum, self.eps)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minstance_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[0m\n\u001b[1;32m   2493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2494\u001b[0m         \u001b[0m_verify_spatial_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m     return torch.instance_norm(\n\u001b[0m\u001b[1;32m   2496\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_input_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2497\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if SAVE_MODELS:\n",
        "  torch.save(G_A.cpu().state_dict(), MODEL_DIR + model_name + \"_GA.pt\")\n",
        "  torch.save(D_B.cpu().state_dict(), MODEL_DIR + model_name + \"_DB.pt\")\n",
        "  torch.save(G_B.cpu().state_dict(), MODEL_DIR + model_name + \"_GB.pt\")\n",
        "  torch.save(D_A.cpu().state_dict(), MODEL_DIR + model_name + \"_DA.pt\")"
      ],
      "metadata": {
        "id": "tXSWLWFIEJH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/ECE-GY 6953 DL/Project/SavedModels/\" -l"
      ],
      "metadata": {
        "id": "PBeMH6r_Eon2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evalutaion"
      ],
      "metadata": {
        "id": "U_XEwmibJQzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Curves"
      ],
      "metadata": {
        "id": "a9b-Id-ZpRCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(losses_G, label=\"Loss G\")\n",
        "plt.plot(losses_D_B, label=\"Loss D_B\")\n",
        "plt.plot(losses_D_A, label=\"Loss D_A\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Losses\")\n",
        "plt.legend()\n",
        "\n",
        "if SAVE_LOSS_PLOTS:\n",
        "  plt.savefig(VISUAL_DIR + model_name + \"_losses.png\")"
      ],
      "metadata": {
        "id": "nTcnIZiLybtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Sample Visualization"
      ],
      "metadata": {
        "id": "ystC1PNWpUNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this block when loading from saved models\n",
        "# G_A = Generator(in_channel=3, out_channel=3).to(DEVICE)"
      ],
      "metadata": {
        "id": "_NCq0OUaUtm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_real = next(iter(test_data_loader))[0][0] # A\n",
        "plt.imshow(test_real.permute(1,2,0))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EnQ_XRto4gqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_A = G_A.to(DEVICE)\n",
        "G_A.eval()\n",
        "test_fake = G_A(test_real.unsqueeze(0).float().to(DEVICE)).squeeze(0).cpu().detach()"
      ],
      "metadata": {
        "id": "tYjqBmKY5L1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_fake_post = post_processing_image(test_fake)\n",
        "plt.imshow(test_fake_post)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V3QiFiTi5SDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate fake images for multiple test samples\n",
        "G_A = G_A.to(DEVICE)\n",
        "G_B = G_B.to(DEVICE)\n",
        "G_A.eval()\n",
        "G_B.eval()\n",
        "output_dir = VISUAL_DIR + \"GeneratedImages/\"\n",
        "for i, (test_A_real, test_B_real) in enumerate(test_data_loader):\n",
        "  # Test only some samples\n",
        "  if i == 20:\n",
        "    break\n",
        "  \n",
        "  test_A_fake = G_A(test_A_real.float().to(DEVICE))\n",
        "  test_B_fake = G_B(test_B_real.float().to(DEVICE))\n",
        "  save_image(test_A_fake, output_dir + \"A_\" + str(i) + \".png\")\n",
        "  save_image(test_B_fake, output_dir + \"B_\" + str(i) + \".png\")"
      ],
      "metadata": {
        "id": "tGXC4_EhnWyx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "a39ea680-017d-4976-df81-28cd0ae06d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-d1e648948e7b>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mtest_A_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_A_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mtest_B_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_B_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_A_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"A_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_B_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"B_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, fp, format, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ECE-GY 6953 DL/Project/Visualizations/GeneratedImages/A_0.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FCN Scores"
      ],
      "metadata": {
        "id": "R6Xj_9pruOXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://efrosgans.eecs.berkeley.edu/pix2pix/datasets/cityscapes.tar.gz"
      ],
      "metadata": {
        "id": "sfGARmz1uQ1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -zxvf ./cityscapes.tar.gz"
      ],
      "metadata": {
        "id": "X3uXSKlF0349"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open(\"/content/cityscapes/train/1.jpg\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-sJ04YqwzM47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./cityscapes/train/*txt"
      ],
      "metadata": {
        "id": "aQGDAkRy3beo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/phillipi/pix2pix/blob/master/scripts/eval_cityscapes/evaluate.py"
      ],
      "metadata": {
        "id": "bLwM2Eyo6Pqh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}